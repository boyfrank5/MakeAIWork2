{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input AQL paramaters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchOneAql = 'class: 1'\n",
    "batchOneNormal = '80'\n",
    "batchOneRot = '0'\n",
    "batchOneScab = '0'\n",
    "batchOneBlotch = '0'\n",
    "\n",
    "batchTwoAql = 'class: 2'\n",
    "batchTwoNormal = '60'\n",
    "batchTwoRot = '5'\n",
    "batchTwoScab = '15'\n",
    "batchTwoBlotch = '10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De 'input' zinnen en het model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 most similar pairs:\n",
      "The amount of blotch apples in batch one: 0. \t The amount of blotch apples in batch two: 10. \t 0.9558\n",
      "The amount of scab apples in batch one: 0. \t The amount of scab apples in batch two: 15. \t 0.9453\n",
      "The amount of normal apples in batch one: 80. \t The amount of normal apples in batch two: 60. \t 0.9331\n",
      "The amount of rotten apples in batch one: 0. \t The amount of rotten apples in batch two: 5. \t 0.9288\n",
      "The class of batch one is: class: 1. \t The class of batch two is: class: 2. \t 0.8794\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# De antwoorden te de chatbot returned:\n",
    "sentences = [(f'The class of batch one is: {batchOneAql}.'),\n",
    "             (f'The amount of normal apples in batch one: {batchOneNormal}.'),\n",
    "             (f'The amount of rotten apples in batch one: {batchOneRot}.'),\n",
    "             (f'The amount of scab apples in batch one: {batchOneScab}.'),\n",
    "             (f'The amount of blotch apples in batch one: {batchOneBlotch}.'),\n",
    "             (f'The class of batch two is: {batchTwoAql}.'),\n",
    "             (f'The amount of normal apples in batch two: {batchTwoNormal}.'),\n",
    "             (f'The amount of rotten apples in batch two: {batchTwoRot}.'),\n",
    "             (f'The amount of scab apples in batch two: {batchTwoScab}.'),\n",
    "             (f'The amount of blotch apples in batch two: {batchTwoBlotch}.'),\n",
    "             \n",
    "             (f'Hello, what would you like to know?'),\n",
    "             (f'80 apples are inspected for the AQL test.'),\n",
    "             (f'We use a batch size of eighty apples for the AQL process!'),\n",
    "             (f'Here you will find a great apple pie recipe: www.omasappeltaart.nl.')\n",
    "             \n",
    "             ]\n",
    "\n",
    "#Encode all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])\n",
    "\n",
    "#Sort list by the highest cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(\"Top-5 most similar pairs:\")\n",
    "\n",
    "for score, i, j in all_sentence_combinations[0:5]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[0.0536, 0.0986, 0.0908, 0.0332, 0.0171, 0.0555, 0.0892, 0.1012, 0.0677,\n",
      "         0.0419, 0.3984, 0.0114, 0.0543, 0.0088]])\n",
      "Hello, what would you like to know?\n",
      "Similarity: tensor([[0.3474, 0.7794, 0.9141, 0.7472, 0.7606, 0.3355, 0.7611, 0.8973, 0.7235,\n",
      "         0.7517, 0.0366, 0.5423, 0.5650, 0.4030]])\n",
      "The amount of rotten apples in batch one: 0.\n",
      "Similarity: tensor([[ 0.3214,  0.8168,  0.7252,  0.7823,  0.9270,  0.3709,  0.8529,  0.7403,\n",
      "          0.7833,  0.9553, -0.0020,  0.5264,  0.6237,  0.4395]])\n",
      "The amount of blotch apples in batch two: 10.\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "while i < 3:\n",
    "  QuestionChatbot = input()\n",
    "  theQuestion = model.encode(QuestionChatbot, convert_to_tensor=True)\n",
    "  \n",
    "  answerArray = util.dot_score(theQuestion, embeddings)\n",
    "  print(\"Similarity:\", util.dot_score(theQuestion, embeddings))\n",
    "  answerlocation = answerArray.argmax()\n",
    "  print(sentences[answerlocation.item()])\n",
    "  i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08dcd7b465d662d455112702df3945fb76eb8b6c054b50adde9f3b27fa63f4f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook provides an environment to test the different models generated by different train datasets. \n",
    "\n",
    "1. Kies het model welke je wilt gebruiken voor de 'Confusion Matrix'\n",
    "2. Evalueer de 'test accuracy'\n",
    "3. De geschreven functie van een 'Confusion Matrix'\n",
    "4. Genereer een 'Confusion Matrix'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kies het model welke je wilt gebruiken voor de 'Confusion Matrix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = load_model('models/cleanedAndAugumented_M3_100px.h5')\n",
    "# img_height = 100\n",
    "# img_width = 100\n",
    "\n",
    "# model2 = load_model('models/cleanedAndAugumented_470images_M3_180px.h5')\n",
    "# img_height = 180\n",
    "# img_width = 180\n",
    "\n",
    "# model3 = load_model('models/cleanedAndAugumented_470images_M3_256px.h5')\n",
    "# img_height = 256 \n",
    "# img_width = 256\n",
    "\n",
    "# model4 = load_model('models/cleanedAndAugumented_470images_M3_180px.h5')\n",
    "# img_height = 180\n",
    "# img_width = 180\n",
    "\n",
    "# model5 = load_model('models/cleanedAndAugumented_470images_M3_256px.h5')\n",
    "# img_height = 256\n",
    "# img_width = 256\n",
    "\n",
    "# model6 = load_model('models/cleanedAndAugumented_470images_M2_256px.h5')\n",
    "# img_height = 256\n",
    "# img_width = 256\n",
    "\n",
    "# model7 = load_model('models/Train_DataPieterAugumented_100px.h5')\n",
    "# img_height = 100\n",
    "# img_width = 100\n",
    "\n",
    "# model8 = load_model('models/Train_augumented_dataset_M2_180.h5')\n",
    "# img_height = 180\n",
    "# img_width = 180\n",
    "\n",
    "# model9 = load_model('models/Train_augumented_dataset_M2_augLayer_180.h5')\n",
    "# img_height = 180\n",
    "# img_width = 180\n",
    "\n",
    "# model10 = load_model('models/Train_augumented_dataset_M3_auglayer_256px.h5.h5')\n",
    "# img_height = 256\n",
    "# img_width = 256\n",
    "\n",
    "MobileNetV2 = load_model('models/mobileNetV2_256px.h5')\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evalueer de 'test accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/Test'\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  seed=123,\n",
    "  shuffle=False,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = MobileNetV2.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. De geschreven functie van een 'Confusion Matrix'\n",
    "\n",
    "Door de 'Confusion Martrix' in een functie te schrijven kan ik de functie makkelijk aanroepen per model. Zeker met het aantal modellen ik heb is dit geen overbodige luxe. Mochten jullie tips hebben hoe ik deze notebook, of in python code, netter kan opzetten dan leer ik daar graag van. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(model, img_height, img_width, test_data_dir = '/Users/boyfrankclaesen/workspace/makeAIWork2/projects/apple_disease_classification/imageClassifier/data/Test'):\n",
    "  \n",
    "  test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "      test_data_dir,\n",
    "      shuffle=False,\n",
    "      image_size=(img_height, img_width),\n",
    "      batch_size = batch_size)\n",
    "  test_label = test_ds.class_names\n",
    "  print(test_label)\n",
    "  \n",
    "  batchPredictions = model.predict(test_ds)\n",
    "  predicted_categories = tf.argmax(batchPredictions, axis=1)\n",
    "  true_categories = tf.concat([y for x, y in test_ds], axis=0)\n",
    "  result_confusion_matrix = confusion_matrix(true_categories, predicted_categories)\n",
    "  cm_display = ConfusionMatrixDisplay(confusion_matrix = result_confusion_matrix, display_labels = ['Blotch', 'Normal', 'Rot', 'Scab'])\n",
    "\n",
    "  cm_display.plot()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Genereer een 'Confusion Matrix'\n",
    "\n",
    "Selecteer wederom het model het model. Let er op dat deze overeenkomt met de ingeladen data. Data van model1 hoort bij confusionMatrix1, model2 bij confusionMatrix2 en zo door. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusionMatrix(model1, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusionMatrix(model2, 180, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusionMatrix(model3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusionMatrix(model4, 180, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusionMatrix(model5, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusionMatrix(model6, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusionMatrix(model7, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusionMatrix(model8, 180, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusionMatrix(model9, 180, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(MobileNetV2, 256, 256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a868478128082cb5ea3f8e684dd7cf0a14a2d1262b4ff6302d99ea6747d278e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array \n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deze tweede 'model generator' genaamd 'modelGenerator2' wil ik de data op dezelfde manier inladen als wij geleerd hebben in de Notebook Numpy2. De code die gebruikt wordt voor het inladen in 'modelGenerator' komt uit de de tensorflow tutorial:  https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inladen van de data\n",
    "\n",
    "De 'augumented' data is onderscheiden door de soort bewerking voor de bestandsnaam toe te voegen. Deze zijn te herkennnen aan de namen 'flipped', 'black' en 'duotone'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgHeight = 100\n",
    "imgWidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtFiles = list() # deze lijst wordt aangemaakt om later hier onder te kunnen gebruiken bij het aanmaken van de lijsten met bestandsnamen uit de verschillende klasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Blotch', 'Normal', 'Rot', 'Scab']\n",
    "\n",
    "trainDir = \"data/Train_cleaned_and_augumented\"\n",
    "\n",
    "for category in categories:\n",
    "  imgDir = f\"{trainDir}/{category}_Apple/\"\n",
    "  for filename in os.listdir(imgDir): \n",
    "    txtFile = os.path.join(imgDir, filename)\n",
    "    txtFiles.append(txtFile) \n",
    "    # print(txtFile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data inlezen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtFiles = [x for x in txtFiles if \".jpeg\" in x] # Ook al weet ik dat er enkel jpg afbeeldingen in mijn dataset staan filter ik de data op 'jpg'. Dit doe ik om de 'hidden files' die in MacOs gebakken zitten (.DS_Store') te filteren.\n",
    "print(len(txtFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(txtFiles)\n",
    "# print(txtFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageObjects= list()\n",
    "\n",
    "for txtFile in txtFiles:\n",
    "    imageObjects.append (np.asarray(Image.open(txtFile)).astype('uint8')/255) # Afbeelding wordt genormaliseerd.\n",
    "\n",
    "imageObjects = np.array(imageObjects) # List wordt omgezet in array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(imageObjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gebruik de bestandsnamen voor het verkrijgen van de labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageLabels = np.empty(len(txtFiles), dtype = 'S20')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for label in txtFiles:\n",
    "    txtFiles[i] = label.split('/')[2]\n",
    "    i += 1\n",
    "    \n",
    "labelNames, labelNumbers = np.unique(txtFiles, return_inverse=True)\n",
    "\n",
    "labelDict = dict(zip(np.unique(labelNumbers), labelNames))\n",
    "\n",
    "# np.array(np.unique(labelNumbers, return_counts=True)).T # demonstratie van methode unique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labelNames)\n",
    "print(labelNumbers)\n",
    "print(labelDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtFilesSel = []\n",
    "imageObjectSel = []\n",
    "indexRanges = [(0,888),(888,1360),(1360,2272),(2272,2949)] # kijk of je dit nog kunt automatiseren door te koppelen aan de lengte van...\n",
    "\n",
    "\n",
    "\n",
    "for indexR in indexRanges:\n",
    "    for number in range (470): # Nadeel -> wordt elke keer opnieuw bepaald\n",
    "        randomIndex = random.choice(range(indexR[0],indexR[1]))\n",
    "        txtFilesSel.append(txtFiles[randomIndex])\n",
    "        imageObjectSel.append(imageObjects[randomIndex])\n",
    "\n",
    "imageObject = np.array(imageObjectSel) # omzettend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(imageObjectSel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(txtFilesSel[1])\n",
    "# print(imageObjectSel)\n",
    "# type(imageObjects)\n",
    "# print(txtFiles[888])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data splitten</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet, testSet, trainLabels, testLabels = train_test_split(imageObjects, labelNumbers, stratify = labelNumbers, train_size = 0.75, random_state=42)\n",
    "print(trainSet.shape)\n",
    "nrOfImages = len(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nrOfImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data inspecteren</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspectData():\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        number = i\n",
    "        plt.imshow(trainSet[number])\n",
    "        plt.xlabel(labelNames[trainLabels[number]]) \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspectData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bouwen van het model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #model 2 geinspireerd van nick nochnack\n",
    "\n",
    "model = Sequential()\n",
    "num_classes = len(categories)\n",
    "\n",
    "model.add(layers.Rescaling(1./255, input_shape=(imgHeight, imgWidth, 3)))\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(num_classes))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Definieer de trainparameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "gdAlgorithm = keras.optimizers.Adam(learning_rate=0.001)\n",
    "nrOfEpochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train het model<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=gdAlgorithm, loss=lossFunction, metrics=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainSet, trainLabels, epochs=nrOfEpochs, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(os.path.join(f'models/[new]px.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evalueer het model<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = '/Users/boyfrankclaesen/workspace/makeAIWork2/projects/apple_disease_classification/classifier/data/Test'\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_data_dir,\n",
    "  seed=123,\n",
    "  image_size=(imgHeight, imgWidth),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = model.evaluate(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a868478128082cb5ea3f8e684dd7cf0a14a2d1262b4ff6302d99ea6747d278e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

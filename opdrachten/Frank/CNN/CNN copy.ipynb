{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7930,
     "status": "ok",
     "timestamp": 1665995257208,
     "user": {
      "displayName": "Frank Smitskamp",
      "userId": "16279035265695218862"
     },
     "user_tz": -120
    },
    "id": "sZ1A_bCNnXm_",
    "outputId": "f113e693-a6a2-4a66-b6e9-8d00b77538cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 16:37:01.092169: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load vgg model\n",
    "from keras.applications import vgg16\n",
    "# load the model\n",
    "model = vgg16.VGG16()\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1665995265566,
     "user": {
      "displayName": "Frank Smitskamp",
      "userId": "16279035265695218862"
     },
     "user_tz": -120
    },
    "id": "waqLDNSyndlo",
    "outputId": "7d5e3ef6-93e0-4883-9278-97b3b0873c92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1_conv1 (3, 3, 3, 64)\n",
      "block1_conv2 (3, 3, 64, 64)\n",
      "block2_conv1 (3, 3, 64, 128)\n",
      "block2_conv2 (3, 3, 128, 128)\n",
      "block3_conv1 (3, 3, 128, 256)\n",
      "block3_conv2 (3, 3, 256, 256)\n",
      "block3_conv3 (3, 3, 256, 256)\n",
      "block4_conv1 (3, 3, 256, 512)\n",
      "block4_conv2 (3, 3, 512, 512)\n",
      "block4_conv3 (3, 3, 512, 512)\n",
      "block5_conv1 (3, 3, 512, 512)\n",
      "block5_conv2 (3, 3, 512, 512)\n",
      "block5_conv3 (3, 3, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "# summarize filters in each convolutional layer\n",
    "from matplotlib import pyplot\n",
    "# summarize filter shapes\n",
    "for layer in model.layers:\n",
    "\t# check for convolutional layer\n",
    "\tif 'conv' not in layer.name:\n",
    "\t\tcontinue\n",
    "\t# get filter weights\n",
    "\tfilters, biases = layer.get_weights()\n",
    "\tprint(layer.name, filters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "executionInfo": {
     "elapsed": 748,
     "status": "ok",
     "timestamp": 1665995788707,
     "user": {
      "displayName": "Frank Smitskamp",
      "userId": "16279035265695218862"
     },
     "user_tz": -120
    },
    "id": "oyI6P9ofnyww",
    "outputId": "4cd07473-c3ef-4744-ece4-6f54364f8dee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from matplotlib import pyplot\n",
    "# retrieve weights from the second hidden layer\n",
    "filters, biases = model.layers[1].get_weights()\n",
    "# normalize filter values to 0-1 so we can visualize them\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)\n",
    "# plot first few filters\n",
    "n_filters, ix = 6, 1\n",
    "for i in range(n_filters):\n",
    "\t# get the filter\n",
    "\tf = filters[:, :, :, i]\n",
    "\t# plot each channel separately\n",
    "\tfor j in range(3):\n",
    "\t\t# specify subplot and turn of axis\n",
    "\t\tax = pyplot.subplot(n_filters, 3, ix)\n",
    "\t\tax.set_xticks([])\n",
    "\t\tax.set_yticks([])\n",
    "\t\t# plot filter channel in grayscale\n",
    "\t\tpyplot.imshow(f[:, :, j], cmap='gray')\n",
    "\t\tix += 1\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 13603,
     "status": "ok",
     "timestamp": 1665998146023,
     "user": {
      "displayName": "Frank Smitskamp",
      "userId": "16279035265695218862"
     },
     "user_tz": -120
    },
    "id": "DzUjTKIWogKA",
    "outputId": "8cb83fd9-cc3e-4c38-ea3b-8fe64c11b2ec"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m img \u001b[38;5;241m=\u001b[39m expand_dims(img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# prepare the image (e.g. scale pixel values for the vgg)\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m img \u001b[38;5;241m=\u001b[39m preprocess_input(img)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# get feature map for first hidden layer\u001b[39;00m\n\u001b[1;32m     34\u001b[0m feature_maps \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(img)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_input' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# visualize feature maps output from each block in the vgg model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array \n",
    "\n",
    "# from keras.utils import load_img\n",
    "# from keras.utils import img_to_array\n",
    "\n",
    "from keras.models import Model\n",
    "from matplotlib import pyplot\n",
    "from numpy import expand_dims\n",
    "# load the model\n",
    "model = VGG16()\n",
    "# redefine model to output right after the first hidden layer\n",
    "ixs = [2, 5, 9, 13, 17]\n",
    "\n",
    "outputs = [model.layers[i].output for i in ixs]\n",
    "model = Model(inputs=model.inputs, outputs=outputs)\n",
    "\n",
    "# load the image with the required shape\n",
    "img = load_img('draak.webp', target_size=(224, 224))\n",
    "\n",
    "# convert the image to an array\n",
    "img = img_to_array(img)\n",
    "\n",
    "# expand dimensions so that it represents a single 'sample'\n",
    "img = expand_dims(img, axis=0)\n",
    "\n",
    "# prepare the image (e.g. scale pixel values for the vgg)\n",
    "img = preprocess_input(img)\n",
    "\n",
    "# get feature map for first hidden layer\n",
    "feature_maps = model.predict(img)\n",
    "\n",
    "\n",
    "# plot the output from each block\n",
    "square = 8\n",
    "\n",
    "for fmap in feature_maps:\n",
    "\t# plot all 64 maps in an 8x8 squares\n",
    "\tix = 1\n",
    "\tfor _ in range(square):\n",
    "\t\tfor _ in range(square):\n",
    "\t\t\t# specify subplot and turn of axis\n",
    "\t\t\tax = pyplot.subplot(square, square, ix)\n",
    "\t\t\tax.set_xticks([])\n",
    "\t\t\tax.set_yticks([])\n",
    "\t\t\t# plot filter channel in grayscale\n",
    "\t\t\tpyplot.imshow(fmap[0, :, :, ix-1], cmap='gray')\n",
    "\t\t\tix += 1\n",
    "\t# show the figure\n",
    "\t# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.67245603e-07, 1.31448851e-05, 8.65171751e-06, 1.75680834e-04,\n",
       "        2.67811789e-04, 1.19012024e-03, 4.00671452e-05, 1.47679573e-04,\n",
       "        2.27384644e-05, 4.04595514e-04, 2.36525466e-06, 4.65493201e-07,\n",
       "        2.25714102e-05, 6.25922553e-07, 2.89232321e-05, 2.06108075e-06,\n",
       "        3.20319691e-06, 1.10547830e-04, 5.10608561e-06, 9.58797409e-06,\n",
       "        5.68458290e-06, 1.33735724e-02, 3.05539434e-04, 3.56404833e-03,\n",
       "        2.49035249e-04, 4.17172305e-05, 6.43054882e-05, 6.36689001e-05,\n",
       "        2.46079202e-04, 7.78678368e-05, 2.22906783e-06, 1.35914559e-06,\n",
       "        2.23608004e-05, 3.71418835e-04, 3.55387968e-03, 1.24048020e-05,\n",
       "        7.08950174e-05, 8.04255978e-06, 6.10865653e-03, 3.45767196e-03,\n",
       "        1.71352549e-05, 1.84616540e-04, 8.43883434e-04, 5.59676485e-03,\n",
       "        7.32148328e-05, 1.28359770e-05, 4.48794490e-05, 2.41157762e-03,\n",
       "        7.63768458e-06, 4.10892098e-04, 4.31193970e-04, 6.83306098e-01,\n",
       "        2.00050963e-05, 4.71988596e-06, 3.64980806e-05, 8.82328720e-07,\n",
       "        2.11297447e-06, 3.71879059e-06, 2.32434963e-04, 1.54222507e-05,\n",
       "        2.90882617e-05, 5.61660102e-07, 3.76569915e-06, 2.34335821e-05,\n",
       "        1.72828786e-05, 4.67409351e-04, 2.30044127e-04, 1.34299989e-06,\n",
       "        1.38637144e-04, 2.37262226e-03, 1.72840066e-06, 3.47895175e-03,\n",
       "        6.45983346e-06, 3.69240115e-05, 5.73274747e-06, 2.60982438e-06,\n",
       "        5.26298845e-06, 5.22473147e-06, 3.52358256e-05, 5.46128431e-04,\n",
       "        5.20343967e-02, 5.33530292e-05, 4.14483831e-04, 7.78530317e-04,\n",
       "        5.69325603e-05, 1.20974531e-04, 6.00702333e-05, 8.17931941e-05,\n",
       "        3.45053704e-04, 4.68067767e-04, 6.55017629e-06, 2.60524655e-04,\n",
       "        5.20298017e-05, 1.44272475e-04, 2.28063309e-05, 4.78648587e-07,\n",
       "        2.88689698e-05, 7.34057224e-08, 2.52806967e-06, 2.19099093e-05,\n",
       "        4.27424238e-05, 5.44316135e-04, 1.20689538e-06, 5.16398759e-05,\n",
       "        1.16462945e-06, 4.86534532e-07, 1.12651344e-06, 2.76261824e-03,\n",
       "        1.54813504e-04, 6.05590394e-05, 6.19474659e-03, 1.03161577e-02,\n",
       "        8.14691484e-02, 9.50936446e-05, 2.79432890e-04, 4.42474586e-04,\n",
       "        1.80941832e-04, 1.36660959e-03, 1.41175287e-05, 3.16319129e-05,\n",
       "        1.25307670e-05, 9.91765410e-06, 6.21891450e-05, 1.02770491e-05,\n",
       "        2.50284036e-04, 8.45740797e-05, 6.27040770e-03, 4.11429501e-05,\n",
       "        1.95368630e-04, 5.11489809e-04, 2.82600013e-06, 2.19219175e-04,\n",
       "        2.31064463e-04, 9.91418856e-05, 1.20781967e-03, 1.44152946e-04,\n",
       "        1.17750242e-05, 2.88321417e-06, 1.97252564e-04, 5.81886411e-07,\n",
       "        3.03661568e-06, 7.04555214e-06, 3.64870630e-06, 7.59501881e-06,\n",
       "        5.91826043e-04, 4.70599531e-07, 1.21374142e-04, 6.46689441e-05,\n",
       "        8.35193987e-06, 3.12941279e-06, 4.30234786e-06, 3.29079057e-06,\n",
       "        8.43695432e-07, 1.59472086e-06, 8.40804603e-07, 7.70412782e-07,\n",
       "        4.53905045e-07, 1.00227248e-06, 6.70805150e-07, 2.30527371e-06,\n",
       "        4.65633930e-05, 1.85861438e-06, 5.44733538e-08, 1.49149355e-05,\n",
       "        5.55334964e-06, 5.52968504e-06, 2.56328462e-07, 2.55089873e-07,\n",
       "        3.09347047e-06, 8.33551621e-06, 3.33610842e-05, 6.21442553e-07,\n",
       "        7.27089355e-06, 1.86136549e-06, 1.70054489e-06, 1.12895314e-05,\n",
       "        5.88834018e-06, 4.04797574e-05, 3.37619190e-06, 1.38307928e-06,\n",
       "        9.60044417e-08, 4.07802190e-06, 1.01006310e-06, 3.23825989e-05,\n",
       "        3.57582780e-06, 7.63676053e-06, 5.77000674e-06, 4.94506567e-05,\n",
       "        3.55147745e-06, 1.06401353e-06, 8.14677423e-06, 9.18460228e-06,\n",
       "        2.93721359e-06, 2.98381246e-06, 8.74547823e-07, 1.34534059e-06,\n",
       "        1.58981459e-06, 9.09322080e-06, 3.03003185e-06, 1.05825393e-05,\n",
       "        1.72837026e-05, 5.94548681e-07, 9.45234297e-06, 4.47767388e-06,\n",
       "        8.10106769e-07, 3.04120222e-05, 4.54557221e-06, 7.11349571e-07,\n",
       "        1.28995562e-05, 2.53679764e-06, 7.11481846e-07, 8.46527598e-07,\n",
       "        7.35187314e-06, 1.20130539e-06, 2.04040589e-05, 3.41394554e-07,\n",
       "        2.69083648e-06, 4.27708619e-06, 6.03153978e-07, 1.23999939e-06,\n",
       "        1.26692339e-06, 9.71393206e-07, 2.07464473e-06, 1.15178591e-06,\n",
       "        2.14943611e-06, 1.17593174e-06, 3.14564095e-05, 8.95102744e-07,\n",
       "        1.74362879e-06, 1.22627432e-06, 3.97535928e-07, 2.19479170e-06,\n",
       "        3.51082781e-06, 8.05587024e-06, 3.94502695e-06, 3.65461619e-06,\n",
       "        1.61143373e-06, 2.16437593e-06, 8.86633131e-07, 4.89529043e-07,\n",
       "        1.10891938e-06, 1.11555732e-06, 9.78631078e-07, 1.59288027e-06,\n",
       "        1.04421906e-06, 9.84690018e-07, 6.86205158e-06, 2.33300270e-07,\n",
       "        6.42778275e-07, 1.13534452e-06, 1.11138843e-06, 1.09727182e-06,\n",
       "        1.02834420e-05, 3.96528748e-07, 2.77425193e-06, 1.53762176e-06,\n",
       "        8.60066393e-06, 2.64656450e-07, 1.25770919e-06, 6.88462308e-07,\n",
       "        1.83163058e-06, 5.70113343e-07, 1.62238041e-06, 1.25097145e-07,\n",
       "        5.12877477e-06, 1.75796129e-06, 1.87051933e-06, 1.06944697e-06,\n",
       "        1.07539472e-05, 2.40872978e-05, 7.62421450e-06, 1.71358658e-06,\n",
       "        3.51846866e-05, 3.96674568e-06, 3.00806761e-07, 1.14876036e-06,\n",
       "        9.54535790e-06, 1.87954947e-06, 4.28898920e-06, 1.63429195e-05,\n",
       "        2.93638623e-05, 5.61909801e-05, 1.09221719e-05, 2.12742543e-06,\n",
       "        1.38349878e-06, 6.88235887e-05, 1.25560191e-05, 4.48530727e-06,\n",
       "        2.32043694e-05, 1.96649648e-06, 2.05434475e-07, 3.33271396e-06,\n",
       "        8.20375044e-06, 1.74713023e-05, 2.82325800e-06, 8.70143538e-07,\n",
       "        3.81767904e-06, 9.60517468e-07, 3.46451743e-05, 3.37369602e-05,\n",
       "        1.66534355e-05, 1.97206391e-05, 2.12300511e-04, 2.29805992e-05,\n",
       "        1.31725013e-04, 1.26371000e-04, 5.82933472e-03, 2.41365524e-05,\n",
       "        1.07719607e-05, 6.39045611e-05, 1.26362575e-04, 9.42806309e-06,\n",
       "        4.26030783e-05, 1.49397272e-06, 3.17826525e-05, 2.03391005e-06,\n",
       "        6.55065451e-05, 3.11668327e-06, 2.50726844e-05, 2.61283167e-05,\n",
       "        1.03070306e-06, 2.27133118e-04, 1.11814506e-05, 2.27543205e-05,\n",
       "        5.52181700e-06, 2.54698875e-06, 1.39744894e-04, 2.63754069e-03,\n",
       "        7.43523415e-05, 2.04018899e-04, 2.01840265e-07, 2.72375473e-06,\n",
       "        7.42922595e-08, 2.14100197e-07, 7.10269035e-07, 1.66685768e-05,\n",
       "        7.63160870e-07, 1.36550334e-05, 1.14376846e-07, 1.18810433e-07,\n",
       "        2.28190256e-04, 2.39048859e-07, 1.42620604e-06, 5.79184743e-05,\n",
       "        9.58302007e-06, 3.77799624e-05, 1.11457695e-04, 1.35635912e-06,\n",
       "        8.07713004e-05, 2.34385123e-04, 2.19995752e-02, 7.04472943e-04,\n",
       "        1.06018175e-04, 4.14101523e-05, 2.53146805e-04, 3.29489831e-06,\n",
       "        2.51610254e-05, 8.24142990e-06, 2.56901740e-06, 5.07844379e-06,\n",
       "        7.65774166e-06, 4.25031885e-06, 6.17501337e-06, 7.59292961e-05,\n",
       "        3.18335224e-05, 2.86719819e-06, 3.06634348e-07, 1.22264839e-06,\n",
       "        8.91739774e-07, 8.79920026e-06, 3.14811047e-07, 1.15578941e-05,\n",
       "        3.60956278e-06, 6.46167223e-07, 1.01428768e-05, 4.10587381e-06,\n",
       "        5.58903321e-06, 4.90869115e-06, 1.70882140e-06, 1.86345878e-05,\n",
       "        6.72140641e-06, 3.73536477e-06, 4.64926188e-07, 5.91867210e-05,\n",
       "        7.44519639e-05, 3.81548634e-05, 3.26300925e-03, 4.43521884e-07,\n",
       "        1.56777062e-08, 2.87495914e-05, 1.82558812e-04, 3.51995686e-06,\n",
       "        2.87569710e-05, 1.24021053e-05, 7.33197812e-05, 1.27773774e-05,\n",
       "        6.15919242e-04, 9.33687147e-07, 5.21872572e-08, 1.11049585e-05,\n",
       "        1.86958653e-06, 7.95460892e-06, 1.68039651e-06, 4.34757993e-07,\n",
       "        1.04656046e-05, 2.12798041e-05, 2.87473586e-06, 1.24302034e-07,\n",
       "        3.52647675e-07, 2.99295079e-05, 2.11276983e-07, 4.71122689e-07,\n",
       "        1.65227573e-06, 1.34430826e-04, 8.70139047e-06, 1.30085107e-06,\n",
       "        1.44736043e-06, 1.21397688e-05, 1.38727478e-06, 6.76567481e-07,\n",
       "        9.01816009e-07, 5.63032245e-06, 1.81872650e-07, 2.88294768e-06,\n",
       "        1.92314303e-07, 6.93258130e-07, 7.58186980e-06, 4.70113491e-06,\n",
       "        3.48176428e-07, 3.82805820e-06, 8.29244655e-08, 7.29402454e-05,\n",
       "        8.95379287e-07, 1.61621956e-05, 1.43891009e-06, 7.40900816e-07,\n",
       "        1.35031300e-07, 6.65501420e-06, 2.08886235e-07, 1.05324739e-06,\n",
       "        1.08046166e-07, 3.28219336e-08, 6.72598835e-05, 1.06822794e-04,\n",
       "        4.45811395e-07, 1.18452078e-06, 9.77536984e-05, 3.85032508e-05,\n",
       "        3.07359005e-05, 5.02755633e-08, 7.67927588e-07, 4.47651895e-04,\n",
       "        7.24049969e-05, 2.24372843e-06, 4.02395912e-08, 8.31495345e-06,\n",
       "        9.26344306e-04, 8.16249121e-06, 5.69079930e-06, 3.99054588e-05,\n",
       "        9.35470553e-07, 1.61831806e-04, 2.58643445e-06, 9.01486237e-06,\n",
       "        7.45463840e-05, 1.65796846e-05, 1.55140782e-07, 1.66248554e-07,\n",
       "        2.98273505e-07, 5.43147780e-06, 1.16891912e-04, 6.75246383e-06,\n",
       "        4.29433186e-07, 2.88516458e-04, 1.49548521e-06, 6.12353233e-07,\n",
       "        1.60659638e-05, 1.63391553e-06, 1.28992099e-07, 1.01136675e-05,\n",
       "        1.41206243e-07, 1.39829463e-05, 5.84236830e-07, 2.23149982e-05,\n",
       "        1.16691467e-07, 1.74197424e-07, 3.56945316e-06, 2.08408574e-06,\n",
       "        1.52807679e-05, 1.06804191e-05, 3.29297563e-06, 5.57233470e-05,\n",
       "        3.49750565e-07, 4.97185147e-06, 5.94393990e-04, 2.28055364e-06,\n",
       "        2.85849706e-06, 1.38753867e-05, 1.08675147e-06, 4.62392090e-05,\n",
       "        1.37811162e-06, 1.63701159e-04, 6.48653895e-06, 2.99103476e-06,\n",
       "        2.09974569e-05, 2.63236900e-04, 1.69491715e-04, 8.53402526e-06,\n",
       "        7.69774857e-08, 3.64240265e-08, 1.37620202e-06, 9.93232518e-08,\n",
       "        4.82344534e-03, 8.14098428e-07, 8.81089363e-05, 1.93992782e-05,\n",
       "        1.21699493e-04, 5.09267329e-06, 8.38771157e-05, 9.91509097e-08,\n",
       "        9.88060492e-07, 2.09137693e-06, 2.48164554e-07, 5.37429230e-07,\n",
       "        2.69498014e-05, 3.20960635e-06, 1.20871590e-07, 8.02314389e-07,\n",
       "        1.12157977e-05, 2.39931160e-05, 1.75751447e-05, 7.84444092e-06,\n",
       "        5.58715385e-07, 1.54796510e-06, 2.39554339e-07, 7.56227455e-05,\n",
       "        1.71450452e-07, 7.35118647e-06, 1.67978447e-04, 5.24169252e-07,\n",
       "        5.20358981e-07, 4.85133398e-07, 7.73245503e-08, 2.09394352e-06,\n",
       "        1.29177317e-06, 3.20058170e-05, 1.18487907e-04, 3.68506399e-08,\n",
       "        7.83854688e-08, 3.04769983e-05, 9.39488473e-07, 8.17026717e-07,\n",
       "        6.14067039e-06, 7.12806241e-07, 4.41964039e-06, 3.81837033e-08,\n",
       "        5.76956954e-05, 1.18573145e-04, 2.96298435e-06, 9.13763870e-07,\n",
       "        6.74022374e-07, 5.71782778e-07, 1.64181620e-04, 1.67954349e-05,\n",
       "        7.59701879e-06, 1.59616093e-07, 2.17971683e-06, 8.98044050e-07,\n",
       "        8.17765738e-07, 1.35772240e-07, 7.79569324e-04, 6.31869739e-07,\n",
       "        3.48738395e-05, 2.72392615e-08, 8.02358727e-07, 1.14418079e-07,\n",
       "        3.16360592e-06, 2.10377257e-05, 1.70281455e-05, 6.14576174e-06,\n",
       "        1.68112570e-06, 2.76097154e-07, 1.99597977e-07, 8.92664673e-07,\n",
       "        6.67281868e-03, 1.26630921e-05, 1.65216386e-06, 2.50436733e-05,\n",
       "        5.00214924e-07, 3.91941976e-05, 2.08146207e-06, 2.60625911e-05,\n",
       "        3.16701721e-06, 7.50881441e-07, 1.61119111e-04, 5.52822655e-07,\n",
       "        1.96081190e-03, 7.42326665e-05, 3.70019109e-07, 3.46006482e-06,\n",
       "        4.59930161e-03, 3.47694004e-05, 4.90402840e-07, 2.71031713e-08,\n",
       "        3.17356012e-06, 8.30124179e-07, 1.74717425e-04, 8.17363889e-06,\n",
       "        5.13057967e-06, 5.41426402e-07, 3.80910933e-05, 1.32972782e-04,\n",
       "        2.00321097e-07, 1.91851414e-05, 2.65291476e-07, 6.53976485e-06,\n",
       "        1.83873362e-05, 1.23489372e-07, 6.97620198e-05, 1.50875334e-04,\n",
       "        2.36871279e-06, 5.58811337e-07, 1.70308658e-06, 6.14641001e-03,\n",
       "        4.76026031e-07, 1.22053578e-07, 7.56116015e-06, 8.92167577e-07,\n",
       "        1.18813887e-06, 1.62453875e-06, 2.19597678e-06, 1.60402203e-06,\n",
       "        1.95745906e-06, 3.16484802e-05, 5.48396599e-07, 1.09407811e-05,\n",
       "        5.33173989e-06, 2.12643229e-07, 1.91117556e-06, 7.90591571e-07,\n",
       "        2.81236634e-08, 9.56539770e-06, 1.39918967e-07, 5.39308181e-04,\n",
       "        9.93423455e-05, 3.77234915e-06, 8.23111714e-06, 1.10717269e-06,\n",
       "        8.69164438e-08, 3.79463700e-06, 2.83262307e-05, 6.76076013e-07,\n",
       "        6.21135086e-07, 2.37828885e-07, 8.31381556e-07, 1.02472632e-06,\n",
       "        9.34305319e-07, 1.98195949e-06, 6.59128909e-06, 4.96055100e-06,\n",
       "        5.02034041e-08, 2.79497598e-08, 4.60061028e-06, 1.13623873e-05,\n",
       "        6.50310812e-06, 1.13428712e-06, 1.74730906e-06, 7.35054164e-06,\n",
       "        6.96009301e-05, 1.04625360e-06, 1.44511648e-06, 8.59185911e-06,\n",
       "        1.32694777e-05, 2.13950693e-06, 1.68205515e-05, 2.14924242e-07,\n",
       "        2.19242665e-05, 1.33436651e-03, 7.28927125e-06, 1.41701137e-04,\n",
       "        2.02540032e-05, 2.96519488e-06, 1.76584945e-05, 1.99291276e-06,\n",
       "        5.56286759e-05, 1.34276220e-07, 1.09903135e-06, 4.71802741e-06,\n",
       "        1.74518414e-06, 1.46369202e-05, 5.94037999e-07, 8.83727160e-04,\n",
       "        1.29169314e-06, 5.55917609e-07, 1.18226879e-07, 3.42450903e-06,\n",
       "        4.72366401e-06, 1.82475674e-07, 7.16272325e-06, 5.87229879e-05,\n",
       "        3.96982476e-04, 3.95869277e-03, 1.32511772e-07, 1.66376085e-05,\n",
       "        9.75081136e-08, 4.81909943e-08, 5.18751165e-07, 6.42312230e-08,\n",
       "        8.83753237e-04, 2.88722890e-06, 1.03801663e-03, 1.35500868e-05,\n",
       "        1.28671502e-06, 2.42506553e-06, 6.94917935e-06, 2.83568137e-04,\n",
       "        2.11994302e-05, 1.61741283e-07, 3.57655449e-06, 1.60070231e-05,\n",
       "        1.29064702e-07, 1.49294947e-05, 1.35380859e-07, 2.01858365e-05,\n",
       "        4.15811119e-05, 5.06730285e-04, 6.91016203e-06, 3.88613989e-06,\n",
       "        8.98679718e-05, 2.30729202e-05, 2.51442430e-06, 1.20343429e-05,\n",
       "        1.63200798e-06, 1.52527555e-05, 8.28948217e-08, 2.89846685e-05,\n",
       "        7.95138533e-08, 5.53223458e-07, 9.76495630e-06, 4.50022384e-07,\n",
       "        1.03240345e-05, 4.25322605e-06, 8.06738342e-07, 4.16084163e-08,\n",
       "        1.14841316e-06, 1.39552560e-06, 6.34715548e-07, 3.54671641e-07,\n",
       "        4.59367493e-06, 5.15609398e-04, 7.66649555e-06, 1.50697502e-07,\n",
       "        9.51191694e-08, 1.93155774e-05, 7.25870336e-07, 1.39097019e-05,\n",
       "        5.19015657e-06, 7.41723738e-07, 9.91898742e-06, 1.53691224e-06,\n",
       "        1.08861968e-06, 3.14136446e-06, 1.57791121e-07, 3.89311172e-05,\n",
       "        9.43468767e-05, 6.81026431e-05, 1.41752639e-06, 2.43640716e-05,\n",
       "        2.73740557e-06, 1.44373771e-04, 1.00260608e-04, 7.29436138e-08,\n",
       "        1.08641934e-05, 1.38936537e-06, 9.86476334e-06, 2.75279899e-06,\n",
       "        4.59354351e-06, 1.32865168e-03, 9.37860079e-07, 5.22890851e-08,\n",
       "        4.15594423e-06, 9.17357283e-08, 3.98694146e-06, 1.43812143e-03,\n",
       "        3.10855876e-06, 3.74126330e-07, 2.76312517e-06, 2.38159264e-04,\n",
       "        3.73836741e-07, 1.38600313e-07, 6.61394779e-07, 1.60685829e-07,\n",
       "        1.98216458e-05, 1.78450027e-05, 3.18574371e-06, 2.07419453e-05,\n",
       "        2.24035248e-04, 5.46347428e-06, 3.03028997e-07, 1.36407280e-07,\n",
       "        1.48329462e-07, 5.50696350e-05, 4.16201889e-04, 2.17033801e-07,\n",
       "        5.28643523e-06, 3.83415056e-07, 1.72991531e-05, 2.26419434e-06,\n",
       "        8.42804002e-06, 1.82471945e-06, 8.31506384e-08, 2.49354161e-06,\n",
       "        3.20046587e-04, 2.06213258e-06, 5.93638788e-07, 1.15565399e-05,\n",
       "        1.38935948e-05, 2.83109554e-08, 6.13919459e-04, 1.28413944e-06,\n",
       "        2.06683126e-07, 6.10901134e-06, 6.08787047e-08, 7.04441959e-07,\n",
       "        9.58766759e-05, 1.64361450e-06, 2.29093093e-05, 2.35906991e-05,\n",
       "        7.77549722e-05, 5.52584112e-08, 2.15224622e-06, 7.94734569e-06,\n",
       "        1.43679586e-04, 9.37173468e-07, 2.58081769e-07, 3.33825854e-04,\n",
       "        7.58492888e-06, 1.39511451e-06, 3.39518374e-06, 1.53235269e-05,\n",
       "        1.05162442e-04, 8.24383551e-06, 3.74526508e-07, 1.10139363e-05,\n",
       "        1.68401330e-05, 1.06129510e-05, 3.26663343e-04, 9.70735641e-07,\n",
       "        1.06351784e-07, 1.47880963e-03, 9.97917596e-07, 5.05415028e-06,\n",
       "        6.74554201e-07, 4.37540251e-07, 4.18184254e-06, 1.13874348e-05,\n",
       "        3.53387850e-06, 2.44668860e-04, 1.38787627e-05, 1.31740319e-06,\n",
       "        1.19868531e-07, 2.68013500e-05, 3.17596539e-04, 7.10686436e-05,\n",
       "        1.23396057e-06, 1.37413565e-07, 2.16633157e-06, 5.63616993e-07,\n",
       "        1.03771468e-04, 2.32738714e-07, 1.59814954e-06, 4.29743721e-07,\n",
       "        1.08266227e-04, 6.67574977e-06, 7.36153005e-09, 4.23666222e-07,\n",
       "        1.87724402e-06, 7.87792871e-08, 7.44446425e-07, 6.01620468e-06,\n",
       "        1.17805166e-05, 4.97104065e-06, 1.19572824e-05, 6.31631774e-05,\n",
       "        1.58949097e-05, 3.24238827e-05, 1.00948085e-07, 2.33004198e-06,\n",
       "        7.73337320e-07, 1.69377620e-06, 2.36328759e-07, 5.03311931e-05,\n",
       "        5.32249105e-05, 2.23819961e-06, 1.14139311e-05, 4.20871074e-05,\n",
       "        4.84084148e-06, 1.24391818e-05, 1.71907250e-05, 2.35475105e-04,\n",
       "        5.96268023e-07, 4.60002229e-06, 1.04497019e-04, 7.83171072e-06,\n",
       "        7.56166116e-07, 1.73526962e-06, 1.14081467e-06, 5.89138153e-07,\n",
       "        9.99659278e-06, 1.19012753e-07, 7.62458171e-07, 4.57189890e-05,\n",
       "        1.48253741e-06, 1.55629223e-05, 4.27165219e-08, 6.42934594e-07,\n",
       "        8.57316045e-05, 3.41109480e-05, 1.29211571e-06, 8.54503651e-06,\n",
       "        3.33084245e-06, 2.24358828e-05, 1.78024311e-06, 1.25455572e-05,\n",
       "        1.17706786e-05, 1.91402549e-07, 5.21773025e-08, 4.13715469e-07,\n",
       "        4.74260878e-06, 4.78147626e-07, 1.06634630e-07, 2.92766430e-07,\n",
       "        2.95124710e-06, 1.81979072e-08, 2.14168210e-07, 3.72941690e-06,\n",
       "        9.55057185e-05, 1.53592246e-05, 2.72393954e-04, 1.41697899e-06,\n",
       "        1.44316357e-06, 2.94269194e-06, 4.17072442e-07, 2.31176614e-06,\n",
       "        4.34432659e-05, 1.92614129e-06, 4.65902231e-05, 1.93909655e-04,\n",
       "        4.80723884e-06, 1.40569782e-05, 5.21444235e-06, 3.92077254e-07,\n",
       "        6.07074435e-06, 2.51797483e-05, 5.57436782e-04, 1.28277776e-07,\n",
       "        3.23110748e-06, 3.98767543e-06, 2.64912245e-07, 3.40108329e-07,\n",
       "        1.42751578e-05, 2.90972224e-07, 1.48803895e-06, 1.63528810e-07,\n",
       "        5.85316320e-06, 6.05953687e-07, 6.07694460e-07, 5.11177660e-08,\n",
       "        8.45565810e-05, 4.06787052e-07, 9.45309584e-05, 6.38752817e-06,\n",
       "        5.56713967e-05, 5.47865529e-05, 2.40683278e-07, 1.69566174e-05,\n",
       "        5.44512341e-06, 5.68535540e-07, 2.81013181e-05, 2.37501172e-05,\n",
       "        2.14214073e-04, 8.80399682e-07, 6.53668110e-07, 6.50600850e-05,\n",
       "        8.60664102e-07, 9.29409998e-06, 2.33239416e-06, 4.75577963e-06,\n",
       "        6.70920645e-06, 7.28837840e-05, 4.27972045e-05, 4.78933507e-05,\n",
       "        3.95665802e-06, 6.13730981e-06, 7.94672451e-06, 7.46644946e-05,\n",
       "        3.99030017e-04, 4.12593135e-06, 4.31683156e-06, 3.59745923e-06]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print prediction \n",
    "from keras.applications import vgg16\n",
    "model = vgg16.VGG16()\n",
    "predict_img = model.predict(img)\n",
    "predict_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('n01704323', 'triceratops', 0.6833061),\n",
       "  ('n01943899', 'conch', 0.08146915),\n",
       "  ('n01795545', 'black_grouse', 0.052034397),\n",
       "  ('n02417914', 'ibex', 0.021999575),\n",
       "  ('n01608432', 'kite', 0.013373572)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's predict top 5 results\n",
    "top_five_predict = vgg16.decode_predictions(predict_img, top=5)\n",
    "top_five_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMTYnaROJhtjfzGxkKgaKZx",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
